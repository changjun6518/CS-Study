주소의 종류

Physical (absolute) : RAM에 로드됨.

Logical (virtual, relative, relocatable)  : 프로세스마다 독립적으로 가짐. CPU가 인지하는 체계. CPU에 의해 생성.

Symbolic  코드내 변수




주소 바인딩

한 주소에서 다른 주소로 매핑.

a = 10 이라는 코드가 있다고 하면, 이 a라는 변수의 주소를 언제 결정하느냐?



Compile time binding : Compiler가 실행 파일 만들 때 발생.
                       Source code가 기계어(absolute code)로 바뀜.
                       논리주소와 물리주소가 같아 프로세스 로드가 빠르지만, 이미 점유하고 있는 주소와 충돌할 수 있음.
                       다시 컴파일해야 하기 때문에 요즘 안쓰임

Load time binding    : 프로그램이 실행 전에 Main memory에 적재될 때 발생.
                       Compiler가 주소를 결정 못하고 Symbolic address를 Relocatable address로 변환 -> Loader가 Absolute address로 변환.

Run(Execution) time  : 프로그램을 실행 할 때 발생. 
                       그떄그때 메모리 변환을 위해 하드웨어 사용(Logical에 Base address 더함) = Contiguos allocation.
                       MMU가 이 역할을 함.
                       
MMU는 CPU가 메모리에 접근하는 것을 관리하는 컴퓨터 하드웨어 부품.
가상 주소를 실제 주소로 변환, 메모리 보호(Limit address), 캐시 관리, 버스 중재 등의 역할.
                   
                   
                       


메모리 관리 전략

💡 교착상태 vs 기아상태
교착 : 여러 프로세스가 자원에 대해 경쟁하여 서로 끝나기만을 기다리며 아무것도 못하는 상태

발생 조건
1. 상호 배제   : 자원을 배타적으로 점유. 임계구역에 하나의 쓰레드만 진입 가능.
2. 점유 대기   : Shared data를 점유한 상황에서 또 다른 자원을 요청
3. 비선점      : 점유중인 자원을 빼앗아 올 수 없음
4. 순환 대기   : 여러개의 스레드가 원형을 이루며 순환적으로 요구하는 자원을 가지고 있음.

해결법
1. 예방 : 필요조건을 부정
2. 회피 : 조건을 부정하지 않고 알고리즘을 이용해 자원 할당
3. 탐지 : 교착상태를 허용하고 교착상태인 프로세스와 자원을 탐지. 그 후 복구 진행
4. 복구 : 프로세스 하나를 임의로 종료하거나, 교착상태가 해소될때까지 자원을 선점. 이 때 한 프로세스가 계속 희생자가 되면 기아상태 발생 가능
5. 무시 : 교착상태가 잘 발생하지 않는 경우, 프로그래머가 직접 해결



기아 : 특정 프로세스의 우선순위가 낮아서 원하는 자원을 계속 할당 받지 못하는 상태. ex) SJF, SRT

해결법
1. 프로세스 우선순위 수시 변경을 통해 높은 우선순위를 가지도록 기회 부여
2. 오래 기다린 프로세스의 우선순위 높이기
3. 우선순위가 아닌 요청 순서대로 처리하는 요청큐 사용




💡 운영 체제에서 에이징(Aging)는 무엇입니까?
기아상태 예방을 위해 일정 시간마다 우선순위를 높여주는 기법




💡 외부 단편화와 내부 단편화란?
External Fragmentation
프로그램 한 개를 통째로 메모리에 올릴 때, Contiguos allocation에 의해 빈틈없이 메인 메모리에 적재하다가 한 프로그램이 끝나면 메모리에 빈 자리가 생기는데,
다음 프로그램이 이 Hole 보다 메모리가 큰 경우 실행시킬 수 없다.  이렇게 프로그램을 수행하며 메인메모리에 남는 공간이 생기게 되고, 이것은 효율의 저하를 야기한다.
이것이 외부 단편화이다.


Internal Fragmentation
Logical address와 Physical address를 같은 크기로 자르면, 한 프로그램을 연속적으로 배치할 필요가 없게된다.
Hole이 생기지 않아 외부 단편화가 일어나지 않게된다.
프로세스를 쪼개어 메모리에 적재하는 이 Paging 방식은 프로세스의 크기가 페이지의 크기로 나누어 떨어지지 않을때 한 페이지 내에서 잉여 공간이 생기는데,
이를 내부 단편화라고 한다.
순서가 엉켜있는 프로세스의 블록들을 순서가 Linear하게 진행시키기 위해 Page Table이 필요하다.
Page table은 프로세스 당 하나씩 있는데, 프로세스 블록의 Frame number와 여러 정보를 담고있다.

page table은 고정된 크기로 메인메모리를 차지하는데, 이걸 해결하기위해 계층적 페이징, 역 페이지 테이블이 생겼다
MMU는 TLB를 참조하여 실제 주소를 알아낸다

또, Page table을 사용하려면 메인메모리에 두번 접근해야해서 비효율적인데 이걸 해결하기 위해 자주사용된 페이지 테이블의 엔트리의 집합인 TLB(Translation lookaside buffer) 라는 캐시를 이용한다.
💡 페이징의 장점과 단점은?
장점 : 한 프로그램을 메모리에 연속적으로 적재할 필요가 없어 External Fragmentation 방지.
단점 : Internal Fragmentation.



💡 메모리 단편화 해결 기법에 대해 설명하시오.
1. 세그맨트를 페이징하는 방식으로 Paging, Segmentation을 혼용. (Segmentation - 논리적 내용을 기반으로 각 다른 크기로 나눔 - 외부 단편화 존재.)
그러나 주소변환을 세그맨트에서, 페이징에서도 해줘야함.

2. 사용중인 영역과 빈 영역을 한 곳으로 모으는 Compaction.
그러나 메모리를 Compaction을 한다 하더라도 그 전에 대상 프로세스를 어딘가에 복사 해놓아야 하는데, 이 과정에서도 I/O problem이 생긴다.
따라서 Paging의 개념이 등장하게 된다.



💡 페이지 교체 알고리즘 중 3가지를 선택해서 설명해주세요.
1. NRU
R(참조)비트와 M(수정)비트를 설정. R비트는 Clock tick마다 리셋됨

우선순위는 위에서부터 동일 그룹 내에선 무작위.
R=0, M=0
R=0, M=1 // R이 리셋. Clock tick을 지남
R=1, M=0 // 아직 Clock tick을 지나지않음
R=1, M=1

적은 오버헤드로 적절한 성능을 가짐.

2. LRU
가장 오랫동안 사용되지 않은 페이지는 앞으로도 사용되지 않을 거라 가정, 시간 지역성을 고려. 

메모리 참조마다 카운터를 증가시키는 등의 방법을 사용하여 가장 오래 사용되지않은 페이지를 찾고, 스왑영역으로 넘김

Queue로 구현 가능.(사용된 페이지를 맨 위로 push, 교체가 필요할 경우 맨 아래를 pop)

프로세스가 주기억장치에 접근할때마다 참조된 페이지 시간을 기록해야 하므로 막대한 오버헤드가 발생




3. Optimal
미래에 사용되지 않을 페이지를 교체.(비현실적)
과거를 통해 유추할 수 밖에 없음.






가상 메모리

💡 가상메모리의 역할은 무엇인가요?
큰 프로세스를 모두 메모리에 올리지 않더라도 실행가능하게 해줌.
필요한 페이지만을 메모리에 올리는 Demand Paging을 사용.



💡 Page Fault에 대해 설명하시오.
CPU가 접근하려는 페이지가 메모리에 없음. Page table의 해당 페이지의 Valid bit 값이 0인 경우인데, 
하드웨어나 소프트웨어가 CPU에 인터럽트 신호를 보냄 -> OS 내부의 Interrupt Service Routine으로 점프 ->
ISR이 디스크에서 페이지를 찾아 프레임에 할당하고, Page table을 갱신한다. -> 다시 명령어를 실행한다.



💡 Demand Paging(요구 페이징)에 대해 설명하시오.
가상 메모리 시스템에서 프로그램 실행 시, 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신 초기에 필요한 것들만 적재하는 전략.
Pure demanding paging - 초기에 아무것도 적재하지않음. 메모리 관리에 효율적이지만, 시작부터 Page fault가 발생하므로 느림.



💡 Swapping이 무엇인가요?
페이지 아웃으로도 메모리 부족을 해결하지 못할 경우, Swap out 대상이 된 프로세스 전체를 swap 영역(secondary storage, backing store)으로 보낸다.
swap 영역의 프로세스에서 이벤트 요청이 오면 다시 swap in.

HDD에 있는 프로세스를 메모리에 로딩하는 것은 느림.
Context switch가 일어나지만, 메모리 효율을 늘림.



💡 페이지 적중율을 극대화 시키기 위한 방법에는 무엇이 있는지 간략히 설명해주세요.
페이지 적중률 : 요구한 페이지가 이미 메모리에 이미 있음. 페이지 교체 필요 X. 즉 페이지 폴트 발생을 낮춤.

시간 지역성(최근 참조된 메모리는 다시 참조될 확률 높음), 공간 지역성(참조된 메모리 근방의 메모리가 참조될 확률 높음)을 이용
페이지의 크기가 작으면 페이지 테이블의 크기가 증가하여 프로세스를 부분적으로 적재해야하고, 페이지 폴트의 부담이 커짐. 페이지의 크기가 클수록 적중률 증가.


💡 Cache 메모리를 사용하는 이유에 대해 설명하시오.
주기억장치에서 자주 사용하는 프로그램과 데이터를 저장해둠.
CPU(빠름)와 Main memory(느림)간의 속도 차에 따른 병목현상을 줄이기 위한 범용 메모리.
Cache의 Hit-rate를 위해 지역성을 이용.
